<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>face_detection TensorFlow.js</title>
  <style>
    body {
      background-color: #1E272E;
      color: #FFFFFF;
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 0;
      padding: 0;
    }
    h1 {
      margin-top: 50px;
      font-size: 2em;
    }
    p {
      margin: 10px 0;
    }
    input[type="text"] {
      padding: 10px;
      border: none;
      border-radius: 5px;
      margin-bottom: 20px;
    }
    button {
      padding: 10px 20px;
      background-color: #4CAF50;
      border: none;
      border-radius: 5px;
      color: #FFFFFF;
      cursor: pointer;
      font-size: 1em;
      margin-top: 20px;
    }
    button:disabled {
      background-color: #777;
    }
    a {
      color: #4CAF50;
      text-decoration: none;
      margin-top: 20px;
      display: inline-block;
    }
    .container {
      margin-top: 20px;
      position: relative;
      width: 256px;
      height: 256px;
      margin-left: auto;
      margin-right: auto;
    }
    #webcam {
      width: 100%;
      height: auto;
    }
    #overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
  </style>
  <script  src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script>
    document.addEventListener('DOMContentLoaded', () =>
    {
        const startButton = document.getElementById('startButton');
        const resultElement = document.getElementById('result');
        const webcamElement = document.getElementById('webcam');
         const canvasElement = document.getElementById('overlay');
        let stream;
        startButton.disabled=false;
    async function loadModel()
    {
    try
    {
      const model = await tf.loadGraphModel('../model_g/movenet/model.json');
      console.log("Model loaded successfully");
      return model;
    }
    catch (error) 
        {
          console.error("Error loading model:", error);
        }
    }
    async function setupWebcam(videoelement) 
    {
        const webcamElement=videoelement;
            return new Promise((resolve, reject) => {
                navigator.mediaDevices.getUserMedia({ video: true })
                    .then(s => {
                        stream = s; 
                        webcamElement.srcObject = stream;
                        webcamElement.style.transform = 'scaleX(-1)';
                        webcamElement.addEventListener('loadeddata', resolve, false);
                    })
                    .catch(reject);
            });
        }
     function stopWebcam()
     {
            if (stream) 
            {
                stream.getTracks().forEach(track => track.stop());
            }
        }
    function addArray(array1, array2)
    {
      if (array1.length !== array2.length) 
      {
    throw new Error("Arrays must have the same length for element-wise addition");
      }
      for (let i = 0; i < array1.length; i++)
       {
    array1[i] += array2[i];
       }
    }
    async function sendDataToServer(data) {
        try {
          const response = await fetch('https://digi-ai.ir/tf/code/signup.php', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify(data)
          });
          if (response.ok) 
          {
            const serverData = await response.json();
            console.log("Data sent successfully");
            if(serverData.success)
            {
                console.log(serverData.message);
                window.location.href = serverData.redirectUrl;
            }
            else
            {
               console.log(serverData.message); 
               window.location.href = serverData.redirectUrl;
            }
          } 
          else
          {
            console.error("Error sending data:", response.statusText);
          }
        } catch (error) {
          console.error("Error sending data:", error);
        }
      }
    function calculateDistancesAndAngles(keypoints) {
        const distances = [];
        const angles = [];
        
        const pairs = [
          [0, 1], // Nose to left eye
          [0, 2], // Nose to right eye
          [1, 2], // Left eye to right eye
          [1, 3], // Left eye to left ear
          [2, 4], // Right eye to right ear
        ];

        pairs.forEach(pair => {
          const [a, b] = pair;
          const dx = keypoints[b][0] - keypoints[a][0];
          const dy = keypoints[b][1] - keypoints[a][1];
          const distance = Math.sqrt(dx * dx + dy * dy);
          const angle = Math.atan2(dy, dx) * (180 / Math.PI); // Angle in degrees

          distances.push(distance);
          angles.push(angle);
        });
        
        console.log('distance',distances);
        console.log('angles',angles);
        return { distances, angles };
      }
    function extract(input)
    {
      let confident=[];
      let Coordinates=[[0,0],[0,0],[0,0],[0,0],[0,0]];//'nose', 'left eye', 'right eye', 'left ear', 'right ear',
      for(let i=0;i<5;i++)
       {
        Coordinates[i][0]=input[i*3];//y
        Coordinates[i][1]=input[i*3+1];//x
        confident.push(input[i*3+2]);
       }
       console.log('confident',confident);
       console.log('coordinate',Coordinates);
       return Coordinates;
    }
    async function startDetection(a,b)
    {
      let model=a; 
      let videoelement=b;
     // await setupWebcam(videoelement);
      let outputSum = [];
      let frameCount = 0;
      let running = true;//برای ادامه دادن یا نه
      const startTime = Date.now();
    async function runInference(model,videoelement) 
    {
      if (!running) return;
      const tensor = tf.browser.fromPixels(videoelement)
                       .resizeNearestNeighbor([256,256])
                        .toInt()
                         .expandDims();    
    
     const predictions = model.execute({'input': tensor});
     const predictionArray = await predictions.array(); 
     tensor.dispose();
     predictions.dispose(); 
     const keypoints = predictionArray[0][0];
     const face_keypoints=keypoints.filter((element, index) => index<15);//5 keypiont for face and each have 3 data
     if(frameCount != 0)
     {
      addArray(outputSum, face_keypoints);
      frameCount++;
     }
     else
     {
      outputSum=[...face_keypoints];//برای جدا کردن کپی از اصلی
      frameCount++;
     }
     if (Date.now() - startTime < 3000 && frameCount<25) 
     {
       requestAnimationFrame(() => runInference(model, videoelement));
     } 
     else
     {
      running = false;
      const dividedArray = outputSum.map(element => element / frameCount);
      console.log('sum',outputSum);
      console.log('divide',dividedArray);
      console.log('framecount',frameCount);
      stopWebcam();
      let username = document.getElementById("username").value;
      let coordinate=extract(dividedArray);
      const { distances, angles }=calculateDistancesAndAngles(coordinate);
       const dataToSend = {distances,angles,username};
         sendDataToServer(dataToSend);
     }   
     }
    runInference(model,videoelement);
    }
  async function drawing(videoelement, canvas) {
  await setupWebcam(videoelement); 
  const ctx = canvas.getContext('2d');

  canvas.width = 256;//videoelement.videoWidth;
  canvas.height = 256;//videoelement.videoHeight;

  function draw() {

    ctx.clearRect(0, 0, canvas.width, canvas.height);
   // ctx.drawImage(videoelement, 0, 0, canvas.width, canvas.height);
    ctx.strokeStyle = 'red';
    ctx.lineWidth = 2;
    ctx.strokeRect(90, 90, 75, 75);
    //vertical line
    ctx.beginPath();
    ctx.moveTo(127.5, 90);
    ctx.lineTo(127.5, 165);
    ctx.stroke(); 
    //horizental line
    ctx.beginPath(); 
    ctx.moveTo(90, 120);
    ctx.lineTo(165, 120);
    ctx.stroke();
    requestAnimationFrame(draw);
  }

  draw();
}
drawing(webcamElement, canvasElement);
startButton.addEventListener('click', () => 
    {
    startButton.disabled=true;
    loadModel().then(model => 
    {
      startDetection(model,webcamElement);
      startButton.disabled=false;
    });
   });
   
});
 </script>
</head>
<body>
  <center>
     <h1> صفحه ثبت نام</h1>
     <div>
         <p>نام کاربری را وارد کنید</p>
          <input id="username" type="text" name="username">
     </div>
    <div style="position: relative; width: 256px; height: 256px;">
     <video id="webcam" width="256" height="256" autoplay muted ></video>
     <canvas id="overlay" width="256" height="256" style="position: absolute; top: 0; left: 0;"></canvas>
    </div>
    <div style="margin-top: 20px;">
         <button id="startButton" disabled>تشخیص</button>
    </div>
         <a href="https://digi-ai.ir/tf/code/tf_login.html">رفتن
         به صفحه ورود</a>
    
   
    </center>
</body>
</html>
